
###

<p align="Center"><B>Creating K8s Cluster</B></p>

###

<p •	Create aws account <br>•	Create admin User with less privileges<br>•	Goto IAM user<br>•	Create a User in IAM<br></p>•	Goto IAM->Click on User->give Username->check the provide user access to the aws Management Console<br>•	Console password->select Autogenerated Password<br>•	Goto Next<br>•	Permission Option<br>•	Select Attach Policy<br>•	In the Permission Policy-> add Administrator Access<br>•	 Goto next and Create User<br>•	Copy Console sign-in details<br>•	Login Admin User<br>Provision Infrastructure on AWS to setup K8s Cluster<br>•	Creating One Control Plane and two worker Nodes<br>•	Goto EC2 Instances<br>•	Click Launch Instances<br>•	Give a name Control-Plane<br>•	Select Ubuntu <br>•	Select Instance Type->t2.medium or more size, depends on application deployments<br>•	Create new Key-pair and save into local <br>•	Let the remaining settings default we are gonna change it to later<br>•	Click on Launch Instance<br>•	Provision Worker Nodes<br>•	Goto Launch Instances<br>•	Select Ubuntu<br>•	Select instance Type -> t2. medium<br>•	Creating new key-pair-> Select existing key-pair which is created for Control-Plane Node<br>•	Number of Instances-> 2<br>•	Launch instances<br>•	Give a name for both nodes as Worker-Node-1 and Worker-Node-2<br><br>•	Connecting to Control Plane Node<br>•	Change the permissions of .pem file -> chmod 400 k8s.pem<br>•	Connecting to Control plane node-> ssh -i K8s.pem ubuntu@public-ip-adderess of Instance<br>	<br><br><br>Kubernetes cluster Installation Steps<br>What we need to install on control plane node and Worker Node<br>•	Container Runtime<br>•	Kubelet<br>•	Kube Proxy<br>Only Control Plane Node<br>•	Api Server<br>•	Scheduler<br>•	Controller Manager<br>•	Etcd	<br>•	Kube Proxy<br>https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/<br>•	On Control Plane Node<br>•	Execute sudo swapoff -a<br>•	Why swap off k8s scheduler determines best available node for which to deploy newly created pods if memory swapping is allowed to occur on host system, this can lead to performance and stability issues within Kubernetes </br></br> <B>Opening Ports on control plane and worker node</B><br> <img width="708" alt="Screenshot 2025-03-19 at 2 24 34 PM" src="https://github.com/user-attachments/assets/ea510f05-33ed-4a85-8d6e-5d7d2c56bee8" /> </br> <br><br><br><br>172.31.0.0/16	
VPC CIDR block ip address<br> Goto to control plane security groups in aws console<br>•	Edit inbound rule<br>•	Add the control plane ports to security group<br> <br><B>Control-Plane-node-SG</B> <img width="1452" alt="Screenshot 2025-03-19 at 2 41 04 PM" src="https://github.com/user-attachments/assets/617b2f43-5749-40d9-9a6d-06aaa18e3265" />
 <br>Worker-Node-SG <img width="1518" alt="Screenshot 2025-03-19 at 2 51 14 PM" src="https://github.com/user-attachments/assets/4df27e75-c196-4876-8e35-3ac672264bc6" />
Set hostnames for all nodes<br>•	On control plane node<br>•	Goto sudo vim /etc/hosts<br>•	Add private ip-address of control plane and worker nodes <br>172.31.6.192 control plane<br>172.31.12.155 workernode-1<br>172.31.3.144 workernode-2<br>•	Execute sudo hostnamectl set-hostname control-plane and give worker node name on worker nodes<br>•	Logout and login instance so hostnames will update<br><br><br><br>Install container-runtime and configure prerequisites<br>Execute the below mentioned instructions: https://ucmo0-my.sharepoint.com/personal/sxg62250_ucmo_edu/Documents/Creating%20K8s%20Cluster.docx?web=1<br>cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf<br>overlay<br>br_netfilter<br>EOF<br><br>sudo modprobe overlay<br>sudo modprobe br_netfilter<br><br># sysctl params required by setup, params persist across reboots<br>cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf<br>net.bridge.bridge-nf-call-iptables  = 1<br>net. bridge. bridge-nf-call-ip6tables = 1<br>net. ipv4.ip_forward = 1<br>EOF<br><br># Apply sysctl params without reboot<br>sudo sysctl --system<br><br>Install containerd:<br>•	sudo apt-get install containerd	<br><br>Customizing containerd<br><br>•	containerd uses a configuration file located in /etc/containerd/config.toml for specifying daemon level options.<br>•	The default configuration can be generated via containerd config default > /etc/containerd/config.toml<br><br>•	Execute containerd config default | sudo tee /etc/containerd/config.toml<br><br>Execute sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml<br><br>•	Check the containerd status sudo systemctl status containerd<br><br><br><br><br><br><br><br><br>We must install containerd in remaining worker node and repeat the same steps<br>•	 Create script for steps installation<br>o	Install-containerd.sh<br>o	chmod +x install-containerd.sh<br><br>#!/bin/bash<br><br># Install and configure prerequisites<br>## load the necessary modules for Containerd<br>cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf<br>overlay<br>br_netfilter<br>EOF<br><br>sudo modprobe overlay<br>sudo modprobe br_netfilter<br><br># sysctl params required by setup, params persist across reboots<br>cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf<br>net.bridge.bridge-nf-call-iptables  = 1<br>net.bridge.bridge-nf-call-ip6tables = 1<br>net.ipv4.ip_forward                 = 1<br>EOF<br><br># Apply sysctl params without reboot<br>sudo sysctl --system<br><br># Install containerd<br>sudo apt-get update<br>sudo apt-get -y install containerd<br><br># Configure containerd with defaults and restart with this config<br>sudo mkdir -p /etc/containerd<br>containerd config default | sudo tee /etc/containerd/config.toml<br>sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml<br>sudo systemctl restart containerd<br><br><br><br><br>Install kubeadm kubelet and kubectl v1.28<br>•	Installing on Control Plane node<br>o	sudo apt-get update<br>o	sudo apt-get install -y apt-transport-https ca-certificates curl gpg<br>o	Download the public signing key for the Kubernetes package repositories. The same signing key is used for all repositories so you can disregard the version in the URL:<br>	curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gp<br><br>	Add the appropriate Kubernetes apt repository<br>•	echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list<br><br>	Update the apt package index, install kubelet, kubeadm and kubectl, and pin their version:<br>o	sudo apt-get update<br>o	sudo apt-get install -y kubelet=1.28.0-1.1 kubeadm=1.28.0-1.1 kubectl=1.28.0-1.1<br>o	sudo apt-mark hold kubelet kubeadm kubectl<br>	Installation on worker nodes<br>o	 Create Script for installation-k8s-components.sh<br>o	chmod +x installation-k8s-components.sh<br> sudo apt-get update<br># apt-transport-https may be a dummy package; if so, you can skip that package<br>sudo apt-get install -y apt-transport-https ca-certificates curl gpg<br><br>curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg<br><br>echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list<br><br>sudo apt-get update<br>sudo apt-get install -y kubelet=1.28.0-1.1 kubeadm=1.28.0-1.1 kubectl=1.28.0-1.1<br>sudo apt-mark hold kubelet kubeadm kubectl<br><br><br><br><br><br>Initialize Cluster with kubeadm on control plane node<br>	sudo kubeadm init<br>Connect to cluster (Kubeconfig & kubectl)<br>	switch to root user on control plane node<br>o	sudo -i<br>o	export KUBECONFIG=/etc/kubernetes/admin.conf<br>	we can put kubeconfig file into default location that kubectl look for it<br>	exit root user<br>	create a folder called ~/.kube <br>o	mkdir -p  ~/.kube<br>o	sudo cp -i /etc/kubernetes/admin.conf ~/.kube/config<br><br> ls -l ~/.kube/config <br>-rw------- 1 root root 5644 Mar 20 05:21 /home/ubuntu/.kube/config<br><br>Currently its on root user we can make it Ubuntu user<br>	this is ID current user echo $(id -u)<br>	this is ID of the group   echo $(id -g)<br>we can make current user and group of kubeconfig file<br>	sudo chown $(id -u):$(id -g) ~/.kube/config <br>	check again users<br>ls -l ~/.kube/config <br>-rw------- 1 ubuntu ubuntu 5644 Mar 20 05:21 /home/ubuntu/.kube/config<br>	it’s changed to ubuntu user<br> <br><br><br><br><br><br><br><br><br><br><br><br><br><br>Install Cilium Network:<br><br>CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)<br>CLI_ARCH=amd64<br>if [ "$(uname -m)" = "aarch64" ]; then CLI_ARCH=arm64; fi<br>curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}<br>sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum<br>sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin<br>rm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}<br><br>•	install Cilium<br>o	Execute cilium install --set ipam.operator.clusterPoolIPv4PodCIDRList="10.0.0.0/9"<br>o	Check Cilium status<br><br> <br><br>Join Worker Nodes to Cluster:<br> Create a token for joining the command<br>Execute this command kubeadm token create --print-join-command<br><br>•	It generate token for joining the nodes <br>o	kubeadm join 172.31.6.192:6443 --token 8b0ppt.oo9vc3b4uengme35 --discovery-token-ca-cert-hash sha256:25752a57488678b55d03995e4420d389fe9348e5356acd9f788d43576c387f97<br><br>o	execute above command in workernode-1 with sudo privilages<br><br>	sudo kubeadm join 172.31.6.192:6443 --token 8b0ppt.oo9vc3b4uengme35 --discovery-token-ca-cert-hash sha256:25752a57488678b55d03995e4420d389fe9348e5356acd9f788d43576c387f97<br><br><br> <br><br>o	Execute the same command on workerNode-2<br>o	Two worker nodes joined to cluster<br> <br><br><br><br><br><br><br><br><br><br><br><br><br>Now we need to add security rules to control-plane-sg this will allow traffic between any pod in the cluster<br><br> <br><br>o	Add same rules to worker node-sg groups<br>o	<br>o	Now check the status for reachable</p>

###

<h2 align="left">I code with</h2>

###

<div align="left">
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/kubernetes/kubernetes-plain.svg" height="40" alt="kubernetes logo"  />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/bash/bash-original.svg" height="40" alt="bash logo"  />
</div>

###
